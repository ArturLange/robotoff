version: "3.9"

services:
  api:
    restart: always
    image: ghcr.io/openfoodfacts/robotoff:${TAG}
    profiles: [robotoff]
    network_mode: "host"
    volumes:
      - api-dataset:/opt/robotoff/datasets
      - ./tf_models:/opt/robotoff/tf_models
      - ./models:/opt/robotoff/models
    mem_limit: 2g

  workers:
    restart: always
    image: ghcr.io/openfoodfacts/robotoff:${TAG}
    profiles: [robotoff]
    network_mode: "host"
    volumes:
      - api-dataset:/opt/robotoff/datasets
      - ./tf_models:/opt/robotoff/tf_models
      - ./models:/opt/robotoff/models
    command: poetry run robotoff-cli run workers
    mem_limit: 8g

  scheduler:
    restart: always
    image: ghcr.io/openfoodfacts/robotoff:${TAG}
    profiles: [robotoff]
    network_mode: "host"
    volumes:
      - api-dataset:/opt/robotoff/datasets
      - ./tf_models:/opt/robotoff/tf_models
      - ./models:/opt/robotoff/models
    command: poetry run robotoff-cli run scheduler
    mem_limit: 4g

  tf_serving:
    restart: always
    image: tensorflow/serving:1.15.0
    profiles: [robotoff]
    ports:
      - 8501:8501
      - 8500:8500
    volumes:
      - ./tf_models:/models
    entrypoint: "tensorflow_model_server --port=8500 --rest_api_port=8501 --model_config_file=/models/models.config"
    mem_limit: 10g

  postgres:
    restart: always
    image: postgres:11.2-alpine
    profiles: [db]
    environment:
      - POSTGRES_PASSWORD
    volumes:
      - postgres-data:/var/lib/postgresql/data
    ports:
      - 5432:5432
    command: postgres -c shared_buffers=1024MB -c work_mem=64MB
    mem_limit: 4g
    shm_size: 1g

  elasticsearch:
    restart: always
    image: raphael0202/elasticsearch
    profiles: [db]
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    mem_limit: 1500m
    volumes:
      - es-data:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
      - 9300:9300

volumes:
  postgres-data:
  api-dataset:
  es-data:
